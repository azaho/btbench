{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading subject 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train/test splits for subject 3...\n",
      "\n",
      "Processing fold 1/5\n",
      "Train data shape: torch.Size([124, 5120])\n",
      "Test data shape: torch.Size([124, 5120])\n",
      "Length of train data: 4303\n",
      "Length of test data: 1076\n",
      "Processing train data...\n",
      "Processing test data...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from btbench_train_test_splits import generate_splits_SS_ST\n",
    "from braintreebank_subject import Subject\n",
    "from scipy import signal\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "def compute_spectrogram(data, fs=2048, max_freq=2000):\n",
    "    \"\"\"Compute spectrogram for a single trial of data.\n",
    "    \n",
    "    Args:\n",
    "        data (numpy.ndarray): Input voltage data of shape (n_channels, n_samples) or (batch_size, n_channels, n_samples)\n",
    "        fs (int): Sampling frequency in Hz\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Spectrogram representation\n",
    "    \"\"\"\n",
    "    # For 1 second of data at 2048Hz, we'll use larger window\n",
    "    nperseg = 256  # 125ms window\n",
    "    noverlap = 0  # 0% overlap\n",
    "    \n",
    "    f, t, Sxx = signal.spectrogram(\n",
    "        data, \n",
    "        fs=fs,\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        window='boxcar'\n",
    "    )\n",
    "    \n",
    "    return np.log10(Sxx[:, (f<max_freq) & (f>0)] + 1e-10)\n",
    "\n",
    "class MLPClassifierGPU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "subject_id = 3\n",
    "trial_id = 0\n",
    "eval_name = \"volume\"\n",
    "k_folds = 5\n",
    "spectrogram = False\n",
    "\"\"\"Run MLP classification for a given subject, trial, and eval_name.\n",
    "\n",
    "Args:\n",
    "    subject_id (int): Subject ID\n",
    "    trial_id (int): Trial ID\n",
    "    eval_name (str): eval_name name (e.g., \"rms\" for volume classification)\n",
    "    k_folds (int): Number of cross-validation folds\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Load subject data\n",
    "print(f\"Loading subject {subject_id}...\")\n",
    "subject = Subject(subject_id, cache=True)\n",
    "subject.load_neural_data(trial_id)\n",
    "\n",
    "# Generate train/test splits\n",
    "print(f\"Generating train/test splits for subject {subject_id}...\")\n",
    "train_datasets, test_datasets = generate_splits_SS_ST(\n",
    "    test_subject=subject,\n",
    "    test_trial_id=trial_id,\n",
    "    eval_name=eval_name,\n",
    "    k_folds=k_folds\n",
    ")\n",
    "\n",
    "# Store results for each fold\n",
    "fold_accuracies = []\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_data, test_data) in enumerate(zip(train_datasets, test_datasets)):\n",
    "    print(f\"\\nProcessing fold {fold + 1}/{len(train_datasets)}\")\n",
    "\n",
    "    print(f\"Train data shape: {train_data[0][0].shape}\")\n",
    "    print(f\"Test data shape: {test_data[0][0].shape}\")\n",
    "    print(f\"Length of train data: {len(train_data)}\")\n",
    "    print(f\"Length of test data: {len(test_data)}\")\n",
    "\n",
    "    sample_time_from, sample_time_to = 1024, 3072 # get the first second of neural data after word onset\n",
    "    \n",
    "    # Convert dataset to tensors\n",
    "    print(f\"Processing train data...\")\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(train_data)):\n",
    "        features, label = train_data[i]\n",
    "        features = features[:, sample_time_from:sample_time_to]\n",
    "        if spectrogram: \n",
    "            features = torch.from_numpy(compute_spectrogram(features.numpy())).float()\n",
    "        X_train.append(features.flatten())\n",
    "        y_train.append(label)\n",
    "    X_train = torch.stack(X_train)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "    print(f\"Processing test data...\")\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(len(test_data)):\n",
    "        features, label = test_data[i]\n",
    "        features = features[:, sample_time_from:sample_time_to]\n",
    "        if spectrogram:\n",
    "            features = torch.from_numpy(compute_spectrogram(features.numpy())).float()\n",
    "        X_test.append(features.flatten())\n",
    "        y_test.append(label)\n",
    "    X_test = torch.stack(X_test)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Move data to GPU\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP...\n",
      "Epoch 0, Loss: 25.5866\n",
      "Epoch 1, Loss: 17.4546\n",
      "Epoch 2, Loss: 14.5913\n",
      "Epoch 3, Loss: 13.3507\n",
      "Epoch 4, Loss: 10.6591\n",
      "Epoch 5, Loss: 6.5103\n",
      "Epoch 6, Loss: 5.4744\n",
      "Epoch 7, Loss: 4.4197\n",
      "Epoch 8, Loss: 4.3732\n",
      "Epoch 9, Loss: 5.2332\n",
      "Epoch 10, Loss: 4.7851\n",
      "Epoch 11, Loss: 5.4961\n",
      "Epoch 12, Loss: 3.4100\n",
      "Epoch 13, Loss: 2.8403\n",
      "Epoch 14, Loss: 1.7685\n",
      "Epoch 15, Loss: 2.0723\n",
      "Epoch 16, Loss: 1.8226\n",
      "Epoch 17, Loss: 1.4923\n",
      "Epoch 18, Loss: 2.0489\n",
      "Epoch 19, Loss: 2.9949\n",
      "Epoch 20, Loss: 2.1192\n",
      "Epoch 21, Loss: 1.5683\n",
      "Epoch 22, Loss: 1.7264\n",
      "Epoch 23, Loss: 1.2500\n",
      "Epoch 24, Loss: 1.3130\n",
      "Epoch 25, Loss: 1.1035\n",
      "Epoch 26, Loss: 1.2370\n",
      "Epoch 27, Loss: 1.4844\n",
      "Epoch 28, Loss: 1.4532\n",
      "Epoch 29, Loss: 1.0816\n",
      "Epoch 30, Loss: 0.9842\n",
      "Epoch 31, Loss: 0.9395\n",
      "Epoch 32, Loss: 1.7183\n",
      "Epoch 33, Loss: 1.9088\n",
      "Epoch 34, Loss: 1.2867\n",
      "Epoch 35, Loss: 0.9715\n",
      "Epoch 36, Loss: 0.7021\n",
      "Epoch 37, Loss: 0.7989\n",
      "Epoch 38, Loss: 0.8460\n",
      "Epoch 39, Loss: 0.6240\n",
      "Epoch 40, Loss: 1.0993\n",
      "Epoch 41, Loss: 0.5955\n",
      "Epoch 42, Loss: 0.6249\n",
      "Epoch 43, Loss: 0.6075\n",
      "Epoch 44, Loss: 0.7867\n",
      "Epoch 45, Loss: 1.1113\n",
      "Epoch 46, Loss: 1.0956\n",
      "Epoch 47, Loss: 2.4913\n",
      "Epoch 48, Loss: 1.3575\n",
      "Epoch 49, Loss: 1.2340\n",
      "Epoch 50, Loss: 1.0147\n",
      "Epoch 51, Loss: 0.8250\n",
      "Epoch 52, Loss: 0.6517\n",
      "Epoch 53, Loss: 0.7343\n",
      "Epoch 54, Loss: 0.5774\n",
      "Epoch 55, Loss: 0.5130\n",
      "Epoch 56, Loss: 0.4687\n",
      "Epoch 57, Loss: 0.4216\n",
      "Epoch 58, Loss: 0.4355\n",
      "Epoch 59, Loss: 0.3502\n",
      "Epoch 60, Loss: 0.3588\n",
      "Epoch 61, Loss: 0.4909\n",
      "Epoch 62, Loss: 0.2906\n",
      "Epoch 63, Loss: 0.3187\n",
      "Epoch 64, Loss: 0.6335\n",
      "Epoch 65, Loss: 1.2225\n",
      "Epoch 66, Loss: 0.8111\n",
      "Epoch 67, Loss: 1.0589\n",
      "Epoch 68, Loss: 0.6349\n",
      "Epoch 69, Loss: 0.5970\n",
      "Epoch 70, Loss: 0.4950\n",
      "Epoch 71, Loss: 0.5086\n",
      "Epoch 72, Loss: 0.4067\n",
      "Epoch 73, Loss: 0.4281\n",
      "Epoch 74, Loss: 0.3280\n",
      "Epoch 75, Loss: 0.3608\n",
      "Epoch 76, Loss: 0.2279\n",
      "Epoch 77, Loss: 0.2512\n",
      "Epoch 78, Loss: 0.3239\n",
      "Epoch 79, Loss: 0.2926\n",
      "Epoch 80, Loss: 0.2376\n",
      "Epoch 81, Loss: 0.1943\n",
      "Epoch 82, Loss: 0.1997\n",
      "Epoch 83, Loss: 0.2362\n",
      "Epoch 84, Loss: 0.2614\n",
      "Epoch 85, Loss: 0.1311\n",
      "Epoch 86, Loss: 0.1420\n",
      "Epoch 87, Loss: 0.1051\n",
      "Epoch 88, Loss: 0.1976\n",
      "Epoch 89, Loss: 0.1556\n",
      "Epoch 90, Loss: 0.1773\n",
      "Epoch 91, Loss: 0.1142\n",
      "Epoch 92, Loss: 0.1273\n",
      "Epoch 93, Loss: 0.1196\n",
      "Epoch 94, Loss: 0.1235\n",
      "Epoch 95, Loss: 0.1287\n",
      "Epoch 96, Loss: 0.0924\n",
      "Epoch 97, Loss: 0.1305\n",
      "Epoch 98, Loss: 0.1871\n",
      "Epoch 99, Loss: 0.2345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "n_classes = len(torch.unique(y_train))\n",
    "model = MLPClassifierGPU(\n",
    "    input_size=X_train.shape[1],\n",
    "    hidden_sizes=[256, 128],\n",
    "    num_classes=n_classes\n",
    ").to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "print(f\"Training MLP...\")\n",
    "model.train()\n",
    "for epoch in range(100):  # Max 100 epochs\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.6041\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.58      0.67       768\n",
      "           1       0.39      0.68      0.49       308\n",
      "\n",
      "    accuracy                           0.60      1076\n",
      "   macro avg       0.60      0.63      0.58      1076\n",
      "weighted avg       0.69      0.60      0.62      1076\n",
      "\n",
      "\n",
      "Overall Results:\n",
      "Mean Accuracy: 0.6041\n",
      "Std Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subject_id': 3,\n",
       " 'trial_id': 0,\n",
       " 'eval_name': 'volume',\n",
       " 'k_folds': 5,\n",
       " 'mean_accuracy': 0.604089219330855,\n",
       " 'std_accuracy': 0.0,\n",
       " 'fold_results': [{'fold': 1,\n",
       "   'accuracy': 0.604089219330855,\n",
       "   'auroc': 0.6651722301136365,\n",
       "   'n_train_samples': 4303,\n",
       "   'n_test_samples': 1076,\n",
       "   'classification_report': {'0': {'precision': 0.8154981549815498,\n",
       "     'recall': 0.5755208333333334,\n",
       "     'f1-score': 0.6748091603053435,\n",
       "     'support': 768.0},\n",
       "    '1': {'precision': 0.3895131086142322,\n",
       "     'recall': 0.6753246753246753,\n",
       "     'f1-score': 0.49406175771971494,\n",
       "     'support': 308.0},\n",
       "    'accuracy': 0.604089219330855,\n",
       "    'macro avg': {'precision': 0.602505631797891,\n",
       "     'recall': 0.6254227543290043,\n",
       "     'f1-score': 0.5844354590125292,\n",
       "     'support': 1076.0},\n",
       "    'weighted avg': {'precision': 0.6935619149433213,\n",
       "     'recall': 0.604089219330855,\n",
       "     'f1-score': 0.6230710562194945,\n",
       "     'support': 1076.0}}}],\n",
       " 'n_classes': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_score = torch.softmax(y_pred, dim=1)\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "# Convert predictions back to CPU for metric calculation\n",
    "y_pred_cpu = y_pred.cpu().numpy()\n",
    "y_test_cpu = y_test.cpu().numpy()\n",
    "y_score_cpu = y_score.cpu().numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_cpu, y_pred_cpu)\n",
    "\n",
    "if n_classes == 2:\n",
    "    auroc = roc_auc_score(y_test_cpu, y_score_cpu[:, 1])\n",
    "else:\n",
    "    auroc_per_class = []\n",
    "    for i in range(n_classes):\n",
    "        y_binary = (y_test_cpu == i).astype(int)\n",
    "        auroc_per_class.append(roc_auc_score(y_binary, y_score_cpu[:, i]))\n",
    "    auroc = np.mean(auroc_per_class)\n",
    "    \n",
    "fold_accuracies.append(accuracy)\n",
    "\n",
    "# Store fold results\n",
    "fold_results.append({\n",
    "    'fold': fold + 1,\n",
    "    'accuracy': float(accuracy),\n",
    "    'auroc': float(auroc),\n",
    "    'n_train_samples': len(y_train),\n",
    "    'n_test_samples': len(y_test),\n",
    "    'classification_report': classification_report(y_test_cpu, y_pred_cpu, output_dict=True)\n",
    "})\n",
    "\n",
    "if n_classes > 2:\n",
    "    fold_results[-1]['auroc_per_class'] = {f'class_{i}': float(auc) for i, auc in enumerate(auroc_per_class)}\n",
    "\n",
    "# Print fold results\n",
    "print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_cpu, y_pred_cpu))\n",
    "\n",
    "# Clean up memory\n",
    "del X_train, y_train, X_test, y_test, y_pred\n",
    "del model, accuracy, auroc\n",
    "if n_classes > 2:\n",
    "    del auroc_per_class, y_score\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Calculate and print overall results\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Std Accuracy: {std_accuracy:.4f}\")\n",
    "\n",
    "# Save results to JSON\n",
    "results = {\n",
    "    'subject_id': subject_id,\n",
    "    'trial_id': trial_id,\n",
    "    'eval_name': eval_name,\n",
    "    'k_folds': k_folds,\n",
    "    'mean_accuracy': float(mean_accuracy),\n",
    "    'std_accuracy': float(std_accuracy),\n",
    "    'fold_results': fold_results,\n",
    "    'n_classes': int(n_classes)\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
